{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T10:31:09.021198Z",
     "start_time": "2025-07-22T10:31:09.009485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Load the dataset\n",
    "df = pd.read_csv('metrike/triton_rezultati.csv')\n",
    "df"
   ],
   "id": "44e6bb1c0f78dfb1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      test          model  batch_size floating_point concurrency  kv_cache  \\\n",
       "0    alpha         gemma3           1           fp16      1:24:2         0   \n",
       "1    alpha         gemma3           2           fp16      1:24:2         0   \n",
       "2    alpha         gemma3           2           fp16      1:24:2         0   \n",
       "3    alpha         gemma3           2           fp16      1:24:2         0   \n",
       "4    alpha         gemma3           2           fp16      1:24:2         0   \n",
       "..     ...            ...         ...            ...         ...       ...   \n",
       "444  kappa  rt-meta-llama           8            f32    1:128:16         0   \n",
       "445  kappa  rt-meta-llama           8            f32    1:128:16         0   \n",
       "446  kappa  rt-meta-llama           8            f32    1:128:16         0   \n",
       "447  kappa  rt-meta-llama           8            f32    1:128:16         0   \n",
       "448  kappa  rt-meta-llama           8            f32    1:128:16         0   \n",
       "\n",
       "     Concurrency  Inferences/Second  Client Send  Network+Server Send/Recv  \\\n",
       "0              1           0.643508           50                       719   \n",
       "1             19           1.185160           54                       819   \n",
       "2             11           1.203680           48                       752   \n",
       "3              5           1.203680           51                       815   \n",
       "4              9           1.203680           54                       820   \n",
       "..           ...                ...          ...                       ...   \n",
       "444           49        3754.660000           86                      4705   \n",
       "445           65        3838.240000          139                      3336   \n",
       "446           97        3867.420000          244                      5185   \n",
       "447           81        3922.710000          216                      4862   \n",
       "448          113        4065.250000          441                      4203   \n",
       "\n",
       "     ...  Server Compute Input  Server Compute Infer  Server Compute Output  \\\n",
       "0    ...                    17               1550278                     39   \n",
       "1    ...                    66               6588780                     81   \n",
       "2    ...                    41               6208113                     74   \n",
       "3    ...                    34               5601306                     73   \n",
       "4    ...                    33               5777241                     83   \n",
       "..   ...                   ...                   ...                    ...   \n",
       "444  ...                    25                 11155                   3780   \n",
       "445  ...                    25                 11742                   3709   \n",
       "446  ...                    26                 12111                   3734   \n",
       "447  ...                    24                 12203                   3737   \n",
       "448  ...                    24                 11820                   3857   \n",
       "\n",
       "     Client Recv  p50 latency  p90 latency  p95 latency  p99 latency  \\\n",
       "0              0      1542649      1545638      1546397      1561484   \n",
       "1              0     32932954     32973698     32975293     34715581   \n",
       "2              0     18114342     18157300     19758219     19796982   \n",
       "3              0      8238339      8254527      8257616      8259402   \n",
       "4              0     14816465     16490745     16580923     18095577   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "444        82483        81683       228828       234515       244643   \n",
       "445       112443       110915       271311       295479       307773   \n",
       "446       167486       198150       348528       357235       383731   \n",
       "447       129274       144325       313809       328600       340716   \n",
       "448       120454       201725       354931       380677       398134   \n",
       "\n",
       "     request/response  response wait  \n",
       "0                  50        1551326  \n",
       "1                  54       30954911  \n",
       "2                  48       18116455  \n",
       "3                  51        8238383  \n",
       "4                  54       14707821  \n",
       "..                ...            ...  \n",
       "444             82569          17868  \n",
       "445            112582          20705  \n",
       "446            167730          29346  \n",
       "447            129490          32031  \n",
       "448            120895          98359  \n",
       "\n",
       "[449 rows x 21 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>model</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>floating_point</th>\n",
       "      <th>concurrency</th>\n",
       "      <th>kv_cache</th>\n",
       "      <th>Concurrency</th>\n",
       "      <th>Inferences/Second</th>\n",
       "      <th>Client Send</th>\n",
       "      <th>Network+Server Send/Recv</th>\n",
       "      <th>...</th>\n",
       "      <th>Server Compute Input</th>\n",
       "      <th>Server Compute Infer</th>\n",
       "      <th>Server Compute Output</th>\n",
       "      <th>Client Recv</th>\n",
       "      <th>p50 latency</th>\n",
       "      <th>p90 latency</th>\n",
       "      <th>p95 latency</th>\n",
       "      <th>p99 latency</th>\n",
       "      <th>request/response</th>\n",
       "      <th>response wait</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alpha</td>\n",
       "      <td>gemma3</td>\n",
       "      <td>1</td>\n",
       "      <td>fp16</td>\n",
       "      <td>1:24:2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.643508</td>\n",
       "      <td>50</td>\n",
       "      <td>719</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>1550278</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>1542649</td>\n",
       "      <td>1545638</td>\n",
       "      <td>1546397</td>\n",
       "      <td>1561484</td>\n",
       "      <td>50</td>\n",
       "      <td>1551326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alpha</td>\n",
       "      <td>gemma3</td>\n",
       "      <td>2</td>\n",
       "      <td>fp16</td>\n",
       "      <td>1:24:2</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1.185160</td>\n",
       "      <td>54</td>\n",
       "      <td>819</td>\n",
       "      <td>...</td>\n",
       "      <td>66</td>\n",
       "      <td>6588780</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>32932954</td>\n",
       "      <td>32973698</td>\n",
       "      <td>32975293</td>\n",
       "      <td>34715581</td>\n",
       "      <td>54</td>\n",
       "      <td>30954911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alpha</td>\n",
       "      <td>gemma3</td>\n",
       "      <td>2</td>\n",
       "      <td>fp16</td>\n",
       "      <td>1:24:2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1.203680</td>\n",
       "      <td>48</td>\n",
       "      <td>752</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>6208113</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>18114342</td>\n",
       "      <td>18157300</td>\n",
       "      <td>19758219</td>\n",
       "      <td>19796982</td>\n",
       "      <td>48</td>\n",
       "      <td>18116455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alpha</td>\n",
       "      <td>gemma3</td>\n",
       "      <td>2</td>\n",
       "      <td>fp16</td>\n",
       "      <td>1:24:2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.203680</td>\n",
       "      <td>51</td>\n",
       "      <td>815</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>5601306</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>8238339</td>\n",
       "      <td>8254527</td>\n",
       "      <td>8257616</td>\n",
       "      <td>8259402</td>\n",
       "      <td>51</td>\n",
       "      <td>8238383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alpha</td>\n",
       "      <td>gemma3</td>\n",
       "      <td>2</td>\n",
       "      <td>fp16</td>\n",
       "      <td>1:24:2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1.203680</td>\n",
       "      <td>54</td>\n",
       "      <td>820</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>5777241</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>14816465</td>\n",
       "      <td>16490745</td>\n",
       "      <td>16580923</td>\n",
       "      <td>18095577</td>\n",
       "      <td>54</td>\n",
       "      <td>14707821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>kappa</td>\n",
       "      <td>rt-meta-llama</td>\n",
       "      <td>8</td>\n",
       "      <td>f32</td>\n",
       "      <td>1:128:16</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>3754.660000</td>\n",
       "      <td>86</td>\n",
       "      <td>4705</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>11155</td>\n",
       "      <td>3780</td>\n",
       "      <td>82483</td>\n",
       "      <td>81683</td>\n",
       "      <td>228828</td>\n",
       "      <td>234515</td>\n",
       "      <td>244643</td>\n",
       "      <td>82569</td>\n",
       "      <td>17868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>kappa</td>\n",
       "      <td>rt-meta-llama</td>\n",
       "      <td>8</td>\n",
       "      <td>f32</td>\n",
       "      <td>1:128:16</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>3838.240000</td>\n",
       "      <td>139</td>\n",
       "      <td>3336</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>11742</td>\n",
       "      <td>3709</td>\n",
       "      <td>112443</td>\n",
       "      <td>110915</td>\n",
       "      <td>271311</td>\n",
       "      <td>295479</td>\n",
       "      <td>307773</td>\n",
       "      <td>112582</td>\n",
       "      <td>20705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>kappa</td>\n",
       "      <td>rt-meta-llama</td>\n",
       "      <td>8</td>\n",
       "      <td>f32</td>\n",
       "      <td>1:128:16</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>3867.420000</td>\n",
       "      <td>244</td>\n",
       "      <td>5185</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>12111</td>\n",
       "      <td>3734</td>\n",
       "      <td>167486</td>\n",
       "      <td>198150</td>\n",
       "      <td>348528</td>\n",
       "      <td>357235</td>\n",
       "      <td>383731</td>\n",
       "      <td>167730</td>\n",
       "      <td>29346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>kappa</td>\n",
       "      <td>rt-meta-llama</td>\n",
       "      <td>8</td>\n",
       "      <td>f32</td>\n",
       "      <td>1:128:16</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>3922.710000</td>\n",
       "      <td>216</td>\n",
       "      <td>4862</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>12203</td>\n",
       "      <td>3737</td>\n",
       "      <td>129274</td>\n",
       "      <td>144325</td>\n",
       "      <td>313809</td>\n",
       "      <td>328600</td>\n",
       "      <td>340716</td>\n",
       "      <td>129490</td>\n",
       "      <td>32031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>kappa</td>\n",
       "      <td>rt-meta-llama</td>\n",
       "      <td>8</td>\n",
       "      <td>f32</td>\n",
       "      <td>1:128:16</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>4065.250000</td>\n",
       "      <td>441</td>\n",
       "      <td>4203</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>11820</td>\n",
       "      <td>3857</td>\n",
       "      <td>120454</td>\n",
       "      <td>201725</td>\n",
       "      <td>354931</td>\n",
       "      <td>380677</td>\n",
       "      <td>398134</td>\n",
       "      <td>120895</td>\n",
       "      <td>98359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>449 rows × 21 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T10:31:25.649613Z",
     "start_time": "2025-07-22T10:31:25.639972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### concatenate test, batch_size, floating_point, kv_cache in one column\n",
    "df['test'] = (df['test'].astype(str) + '_b' + df['batch_size'].astype(str) + '_' + df['floating_point'].astype(str) +\n",
    "              '_kv' + df['kv_cache'].astype(str))\n",
    "df.head()"
   ],
   "id": "e8170209ecbab44b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                test   model  batch_size floating_point concurrency  kv_cache  \\\n",
       "0  alpha_b1_fp16_kv0  gemma3           1           fp16      1:24:2         0   \n",
       "1  alpha_b2_fp16_kv0  gemma3           2           fp16      1:24:2         0   \n",
       "2  alpha_b2_fp16_kv0  gemma3           2           fp16      1:24:2         0   \n",
       "3  alpha_b2_fp16_kv0  gemma3           2           fp16      1:24:2         0   \n",
       "4  alpha_b2_fp16_kv0  gemma3           2           fp16      1:24:2         0   \n",
       "\n",
       "   Concurrency  Inferences/Second  Client Send  Network+Server Send/Recv  ...  \\\n",
       "0            1           0.643508           50                       719  ...   \n",
       "1           19           1.185160           54                       819  ...   \n",
       "2           11           1.203680           48                       752  ...   \n",
       "3            5           1.203680           51                       815  ...   \n",
       "4            9           1.203680           54                       820  ...   \n",
       "\n",
       "   Server Compute Input  Server Compute Infer  Server Compute Output  \\\n",
       "0                    17               1550278                     39   \n",
       "1                    66               6588780                     81   \n",
       "2                    41               6208113                     74   \n",
       "3                    34               5601306                     73   \n",
       "4                    33               5777241                     83   \n",
       "\n",
       "   Client Recv  p50 latency  p90 latency  p95 latency  p99 latency  \\\n",
       "0            0      1542649      1545638      1546397      1561484   \n",
       "1            0     32932954     32973698     32975293     34715581   \n",
       "2            0     18114342     18157300     19758219     19796982   \n",
       "3            0      8238339      8254527      8257616      8259402   \n",
       "4            0     14816465     16490745     16580923     18095577   \n",
       "\n",
       "   request/response  response wait  \n",
       "0                50        1551326  \n",
       "1                54       30954911  \n",
       "2                48       18116455  \n",
       "3                51        8238383  \n",
       "4                54       14707821  \n",
       "\n",
       "[5 rows x 21 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>model</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>floating_point</th>\n",
       "      <th>concurrency</th>\n",
       "      <th>kv_cache</th>\n",
       "      <th>Concurrency</th>\n",
       "      <th>Inferences/Second</th>\n",
       "      <th>Client Send</th>\n",
       "      <th>Network+Server Send/Recv</th>\n",
       "      <th>...</th>\n",
       "      <th>Server Compute Input</th>\n",
       "      <th>Server Compute Infer</th>\n",
       "      <th>Server Compute Output</th>\n",
       "      <th>Client Recv</th>\n",
       "      <th>p50 latency</th>\n",
       "      <th>p90 latency</th>\n",
       "      <th>p95 latency</th>\n",
       "      <th>p99 latency</th>\n",
       "      <th>request/response</th>\n",
       "      <th>response wait</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alpha_b1_fp16_kv0</td>\n",
       "      <td>gemma3</td>\n",
       "      <td>1</td>\n",
       "      <td>fp16</td>\n",
       "      <td>1:24:2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.643508</td>\n",
       "      <td>50</td>\n",
       "      <td>719</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>1550278</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>1542649</td>\n",
       "      <td>1545638</td>\n",
       "      <td>1546397</td>\n",
       "      <td>1561484</td>\n",
       "      <td>50</td>\n",
       "      <td>1551326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alpha_b2_fp16_kv0</td>\n",
       "      <td>gemma3</td>\n",
       "      <td>2</td>\n",
       "      <td>fp16</td>\n",
       "      <td>1:24:2</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1.185160</td>\n",
       "      <td>54</td>\n",
       "      <td>819</td>\n",
       "      <td>...</td>\n",
       "      <td>66</td>\n",
       "      <td>6588780</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>32932954</td>\n",
       "      <td>32973698</td>\n",
       "      <td>32975293</td>\n",
       "      <td>34715581</td>\n",
       "      <td>54</td>\n",
       "      <td>30954911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alpha_b2_fp16_kv0</td>\n",
       "      <td>gemma3</td>\n",
       "      <td>2</td>\n",
       "      <td>fp16</td>\n",
       "      <td>1:24:2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1.203680</td>\n",
       "      <td>48</td>\n",
       "      <td>752</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>6208113</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>18114342</td>\n",
       "      <td>18157300</td>\n",
       "      <td>19758219</td>\n",
       "      <td>19796982</td>\n",
       "      <td>48</td>\n",
       "      <td>18116455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alpha_b2_fp16_kv0</td>\n",
       "      <td>gemma3</td>\n",
       "      <td>2</td>\n",
       "      <td>fp16</td>\n",
       "      <td>1:24:2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.203680</td>\n",
       "      <td>51</td>\n",
       "      <td>815</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>5601306</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>8238339</td>\n",
       "      <td>8254527</td>\n",
       "      <td>8257616</td>\n",
       "      <td>8259402</td>\n",
       "      <td>51</td>\n",
       "      <td>8238383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alpha_b2_fp16_kv0</td>\n",
       "      <td>gemma3</td>\n",
       "      <td>2</td>\n",
       "      <td>fp16</td>\n",
       "      <td>1:24:2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1.203680</td>\n",
       "      <td>54</td>\n",
       "      <td>820</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>5777241</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>14816465</td>\n",
       "      <td>16490745</td>\n",
       "      <td>16580923</td>\n",
       "      <td>18095577</td>\n",
       "      <td>54</td>\n",
       "      <td>14707821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T10:31:33.354969Z",
     "start_time": "2025-07-22T10:31:33.350306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Zadrži samo relevantne kolone\\n\",\n",
    "df_filtered = df[\n",
    " ['test', 'model', 'batch_size', 'floating_point', 'kv_cache',\n",
    "  'Concurrency', 'Inferences/Second',\n",
    "'p50 latency', 'p90 latency', 'p95 latency', 'p99 latency', 'response wait']].copy()\n",
    "\n",
    "# convert latency columns to seconds from microseconds\n",
    "df_filtered['p50 latency'] = round(df_filtered['p50 latency'] / 1000000, 3)\n",
    "df_filtered['p90 latency'] = round(df_filtered['p90 latency'] / 1000000, 3)\n",
    "df_filtered['p95 latency'] = round(df_filtered['p95 latency'] / 1000000, 3)\n",
    "df_filtered['p99 latency'] = round(df_filtered['p99 latency'] / 1000000, 3)"
   ],
   "id": "7e075a0ee93f829a",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T10:31:37.105446Z",
     "start_time": "2025-07-22T10:31:37.102483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Add a combined metric\n",
    "df_filtered['throughput_latency_ratio'] = df_filtered['Inferences/Second'] / df_filtered['p99 latency']\n",
    "# For each test and model, get the row with the highest ratio\n",
    "best_rows = df_filtered.loc[df_filtered.groupby(['test', 'model'])['throughput_latency_ratio'].idxmax()]"
   ],
   "id": "23f073824ecd5c7c",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T10:31:38.062185Z",
     "start_time": "2025-07-22T10:31:38.052249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# order by highest throughput_latency_ratio\n",
    "best_rows = best_rows.sort_values(by='throughput_latency_ratio', ascending=False)\n",
    "# Display the best rows\n",
    "best_rows.reset_index(drop=True, inplace=True)\n",
    "best_rows.head(10)"
   ],
   "id": "d211c3d78f1a67b2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  test          model  batch_size floating_point  kv_cache  \\\n",
       "0   iota_b1_f32_kv8192     rt-mistral           1            f32      8192   \n",
       "1   iota_b4_f32_kv8192     rt-mistral           4            f32      8192   \n",
       "2     kappa_b8_f32_kv0     rt-mistral           8            f32         0   \n",
       "3   iota_b8_f32_kv8192     rt-mistral           8            f32      8192   \n",
       "4  theta_b8_f32_kv4096     rt-mistral           8            f32      4096   \n",
       "5   iota_b4_f32_kv8192  rt-meta-llama           4            f32      8192   \n",
       "6   iota_b1_f32_kv8192  rt-meta-llama           1            f32      8192   \n",
       "7     kappa_b8_f32_kv0  rt-meta-llama           8            f32         0   \n",
       "8   iota_b8_f32_kv8192  rt-meta-llama           8            f32      8192   \n",
       "9   iota_b1_f32_kv8192      rt-gemma3           1            f32      8192   \n",
       "\n",
       "   Concurrency  Inferences/Second  p50 latency  p90 latency  p95 latency  \\\n",
       "0          113          5969.2200        0.019        0.022        0.022   \n",
       "1           17          4654.9900        0.014        0.017        0.018   \n",
       "2           17          6109.4200        0.022        0.024        0.025   \n",
       "3           17          6115.9900        0.022        0.025        0.026   \n",
       "4           17          5347.0600        0.026        0.032        0.033   \n",
       "5           17          2906.7600        0.022        0.030        0.033   \n",
       "6           65          2654.5200        0.024        0.033        0.037   \n",
       "7           17          2976.1300        0.033        0.080        0.084   \n",
       "8            1           346.1320        0.021        0.033        0.034   \n",
       "9            1            13.4986        0.074        0.074        0.075   \n",
       "\n",
       "   p99 latency  response wait  throughput_latency_ratio  \n",
       "0        0.023          16162             259531.304348  \n",
       "1        0.020          11997             232749.500000  \n",
       "2        0.027          18963             226274.814815  \n",
       "3        0.028          17683             218428.214286  \n",
       "4        0.035          14652             152773.142857  \n",
       "5        0.041          13833              70896.585366  \n",
       "6        0.041          15414              64744.390244  \n",
       "7        0.091          14962              32704.725275  \n",
       "8        0.035          14150               9889.485714  \n",
       "9        0.077          73426                175.306494  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>model</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>floating_point</th>\n",
       "      <th>kv_cache</th>\n",
       "      <th>Concurrency</th>\n",
       "      <th>Inferences/Second</th>\n",
       "      <th>p50 latency</th>\n",
       "      <th>p90 latency</th>\n",
       "      <th>p95 latency</th>\n",
       "      <th>p99 latency</th>\n",
       "      <th>response wait</th>\n",
       "      <th>throughput_latency_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iota_b1_f32_kv8192</td>\n",
       "      <td>rt-mistral</td>\n",
       "      <td>1</td>\n",
       "      <td>f32</td>\n",
       "      <td>8192</td>\n",
       "      <td>113</td>\n",
       "      <td>5969.2200</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.023</td>\n",
       "      <td>16162</td>\n",
       "      <td>259531.304348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iota_b4_f32_kv8192</td>\n",
       "      <td>rt-mistral</td>\n",
       "      <td>4</td>\n",
       "      <td>f32</td>\n",
       "      <td>8192</td>\n",
       "      <td>17</td>\n",
       "      <td>4654.9900</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.020</td>\n",
       "      <td>11997</td>\n",
       "      <td>232749.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kappa_b8_f32_kv0</td>\n",
       "      <td>rt-mistral</td>\n",
       "      <td>8</td>\n",
       "      <td>f32</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>6109.4200</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.027</td>\n",
       "      <td>18963</td>\n",
       "      <td>226274.814815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iota_b8_f32_kv8192</td>\n",
       "      <td>rt-mistral</td>\n",
       "      <td>8</td>\n",
       "      <td>f32</td>\n",
       "      <td>8192</td>\n",
       "      <td>17</td>\n",
       "      <td>6115.9900</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.028</td>\n",
       "      <td>17683</td>\n",
       "      <td>218428.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>theta_b8_f32_kv4096</td>\n",
       "      <td>rt-mistral</td>\n",
       "      <td>8</td>\n",
       "      <td>f32</td>\n",
       "      <td>4096</td>\n",
       "      <td>17</td>\n",
       "      <td>5347.0600</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.035</td>\n",
       "      <td>14652</td>\n",
       "      <td>152773.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>iota_b4_f32_kv8192</td>\n",
       "      <td>rt-meta-llama</td>\n",
       "      <td>4</td>\n",
       "      <td>f32</td>\n",
       "      <td>8192</td>\n",
       "      <td>17</td>\n",
       "      <td>2906.7600</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.041</td>\n",
       "      <td>13833</td>\n",
       "      <td>70896.585366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>iota_b1_f32_kv8192</td>\n",
       "      <td>rt-meta-llama</td>\n",
       "      <td>1</td>\n",
       "      <td>f32</td>\n",
       "      <td>8192</td>\n",
       "      <td>65</td>\n",
       "      <td>2654.5200</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.041</td>\n",
       "      <td>15414</td>\n",
       "      <td>64744.390244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kappa_b8_f32_kv0</td>\n",
       "      <td>rt-meta-llama</td>\n",
       "      <td>8</td>\n",
       "      <td>f32</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>2976.1300</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.091</td>\n",
       "      <td>14962</td>\n",
       "      <td>32704.725275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>iota_b8_f32_kv8192</td>\n",
       "      <td>rt-meta-llama</td>\n",
       "      <td>8</td>\n",
       "      <td>f32</td>\n",
       "      <td>8192</td>\n",
       "      <td>1</td>\n",
       "      <td>346.1320</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.035</td>\n",
       "      <td>14150</td>\n",
       "      <td>9889.485714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>iota_b1_f32_kv8192</td>\n",
       "      <td>rt-gemma3</td>\n",
       "      <td>1</td>\n",
       "      <td>f32</td>\n",
       "      <td>8192</td>\n",
       "      <td>1</td>\n",
       "      <td>13.4986</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.077</td>\n",
       "      <td>73426</td>\n",
       "      <td>175.306494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T10:31:44.516142Z",
     "start_time": "2025-07-22T10:31:44.506350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# remove Concurrency column\n",
    "best_rows.drop(columns=['Concurrency'], inplace=True)\n",
    "# Display the best rows\n",
    "best_rows.reset_index(drop=True, inplace=True)\n",
    "best_rows.head(20)"
   ],
   "id": "16ad6464c1f5d788",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                   test          model  batch_size floating_point  kv_cache  \\\n",
       "0    iota_b1_f32_kv8192     rt-mistral           1            f32      8192   \n",
       "1    iota_b4_f32_kv8192     rt-mistral           4            f32      8192   \n",
       "2      kappa_b8_f32_kv0     rt-mistral           8            f32         0   \n",
       "3    iota_b8_f32_kv8192     rt-mistral           8            f32      8192   \n",
       "4   theta_b8_f32_kv4096     rt-mistral           8            f32      4096   \n",
       "5    iota_b4_f32_kv8192  rt-meta-llama           4            f32      8192   \n",
       "6    iota_b1_f32_kv8192  rt-meta-llama           1            f32      8192   \n",
       "7      kappa_b8_f32_kv0  rt-meta-llama           8            f32         0   \n",
       "8    iota_b8_f32_kv8192  rt-meta-llama           8            f32      8192   \n",
       "9    iota_b1_f32_kv8192      rt-gemma3           1            f32      8192   \n",
       "10   iota_b4_f32_kv8192      rt-gemma3           4            f32      8192   \n",
       "11   iota_b8_f32_kv8192      rt-gemma3           8            f32      8192   \n",
       "12     kappa_b8_f32_kv0      rt-gemma3           8            f32         0   \n",
       "13  theta_b8_f32_kv4096      rt-gemma3           8            f32      4096   \n",
       "14     beta_b8_bf16_kv0        mistral           8           bf16         0   \n",
       "15    eta_b8_f16_kv4096         gemma3           8            f16      4096   \n",
       "16   gama_b8_bf16_kv128         gemma3           8           bf16       128   \n",
       "17   eta_b8_bf16_kv4096         gemma3           8           bf16      4096   \n",
       "18     beta_b8_bf16_kv0         gemma3           8           bf16         0   \n",
       "19  delta_b8_bf16_kv256         gemma3           8           bf16       256   \n",
       "\n",
       "    Inferences/Second  p50 latency  p90 latency  p95 latency  p99 latency  \\\n",
       "0          5969.22000        0.019        0.022        0.022        0.023   \n",
       "1          4654.99000        0.014        0.017        0.018        0.020   \n",
       "2          6109.42000        0.022        0.024        0.025        0.027   \n",
       "3          6115.99000        0.022        0.025        0.026        0.028   \n",
       "4          5347.06000        0.026        0.032        0.033        0.035   \n",
       "5          2906.76000        0.022        0.030        0.033        0.041   \n",
       "6          2654.52000        0.024        0.033        0.037        0.041   \n",
       "7          2976.13000        0.033        0.080        0.084        0.091   \n",
       "8           346.13200        0.021        0.033        0.034        0.035   \n",
       "9            13.49860        0.074        0.074        0.075        0.077   \n",
       "10           17.55320        0.227        0.228        0.228        0.228   \n",
       "11           18.66280        0.425        0.429        0.429        0.429   \n",
       "12           18.70150        0.423        0.427        0.427        0.430   \n",
       "13           18.66390        0.424        0.427        0.427        0.431   \n",
       "14           13.64180        2.917        3.045        3.082        3.165   \n",
       "15            4.58020        1.741        1.746        1.747        1.749   \n",
       "16            4.55551        1.747        1.750        1.751        1.753   \n",
       "17            4.50612        1.768        1.771        1.773        1.776   \n",
       "18            4.49378        1.765        1.774        1.774        1.776   \n",
       "19            4.77773        1.671        1.674        1.675        2.197   \n",
       "\n",
       "    response wait  throughput_latency_ratio  \n",
       "0           16162             259531.304348  \n",
       "1           11997             232749.500000  \n",
       "2           18963             226274.814815  \n",
       "3           17683             218428.214286  \n",
       "4           14652             152773.142857  \n",
       "5           13833              70896.585366  \n",
       "6           15414              64744.390244  \n",
       "7           14962              32704.725275  \n",
       "8           14150               9889.485714  \n",
       "9           73426                175.306494  \n",
       "10         223045                 76.987719  \n",
       "11         418648                 43.503030  \n",
       "12         420231                 43.491860  \n",
       "13         418916                 43.303712  \n",
       "14        2926345                  4.310205  \n",
       "15        1749885                  2.618754  \n",
       "16        1756092                  2.598694  \n",
       "17        1774836                  2.537230  \n",
       "18        1775727                  2.530282  \n",
       "19        1676417                  2.174661  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>model</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>floating_point</th>\n",
       "      <th>kv_cache</th>\n",
       "      <th>Inferences/Second</th>\n",
       "      <th>p50 latency</th>\n",
       "      <th>p90 latency</th>\n",
       "      <th>p95 latency</th>\n",
       "      <th>p99 latency</th>\n",
       "      <th>response wait</th>\n",
       "      <th>throughput_latency_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iota_b1_f32_kv8192</td>\n",
       "      <td>rt-mistral</td>\n",
       "      <td>1</td>\n",
       "      <td>f32</td>\n",
       "      <td>8192</td>\n",
       "      <td>5969.22000</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.023</td>\n",
       "      <td>16162</td>\n",
       "      <td>259531.304348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iota_b4_f32_kv8192</td>\n",
       "      <td>rt-mistral</td>\n",
       "      <td>4</td>\n",
       "      <td>f32</td>\n",
       "      <td>8192</td>\n",
       "      <td>4654.99000</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.020</td>\n",
       "      <td>11997</td>\n",
       "      <td>232749.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kappa_b8_f32_kv0</td>\n",
       "      <td>rt-mistral</td>\n",
       "      <td>8</td>\n",
       "      <td>f32</td>\n",
       "      <td>0</td>\n",
       "      <td>6109.42000</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.027</td>\n",
       "      <td>18963</td>\n",
       "      <td>226274.814815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iota_b8_f32_kv8192</td>\n",
       "      <td>rt-mistral</td>\n",
       "      <td>8</td>\n",
       "      <td>f32</td>\n",
       "      <td>8192</td>\n",
       "      <td>6115.99000</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.028</td>\n",
       "      <td>17683</td>\n",
       "      <td>218428.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>theta_b8_f32_kv4096</td>\n",
       "      <td>rt-mistral</td>\n",
       "      <td>8</td>\n",
       "      <td>f32</td>\n",
       "      <td>4096</td>\n",
       "      <td>5347.06000</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.035</td>\n",
       "      <td>14652</td>\n",
       "      <td>152773.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>iota_b4_f32_kv8192</td>\n",
       "      <td>rt-meta-llama</td>\n",
       "      <td>4</td>\n",
       "      <td>f32</td>\n",
       "      <td>8192</td>\n",
       "      <td>2906.76000</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.041</td>\n",
       "      <td>13833</td>\n",
       "      <td>70896.585366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>iota_b1_f32_kv8192</td>\n",
       "      <td>rt-meta-llama</td>\n",
       "      <td>1</td>\n",
       "      <td>f32</td>\n",
       "      <td>8192</td>\n",
       "      <td>2654.52000</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.041</td>\n",
       "      <td>15414</td>\n",
       "      <td>64744.390244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kappa_b8_f32_kv0</td>\n",
       "      <td>rt-meta-llama</td>\n",
       "      <td>8</td>\n",
       "      <td>f32</td>\n",
       "      <td>0</td>\n",
       "      <td>2976.13000</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.091</td>\n",
       "      <td>14962</td>\n",
       "      <td>32704.725275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>iota_b8_f32_kv8192</td>\n",
       "      <td>rt-meta-llama</td>\n",
       "      <td>8</td>\n",
       "      <td>f32</td>\n",
       "      <td>8192</td>\n",
       "      <td>346.13200</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.035</td>\n",
       "      <td>14150</td>\n",
       "      <td>9889.485714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>iota_b1_f32_kv8192</td>\n",
       "      <td>rt-gemma3</td>\n",
       "      <td>1</td>\n",
       "      <td>f32</td>\n",
       "      <td>8192</td>\n",
       "      <td>13.49860</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.077</td>\n",
       "      <td>73426</td>\n",
       "      <td>175.306494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>iota_b4_f32_kv8192</td>\n",
       "      <td>rt-gemma3</td>\n",
       "      <td>4</td>\n",
       "      <td>f32</td>\n",
       "      <td>8192</td>\n",
       "      <td>17.55320</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.228</td>\n",
       "      <td>223045</td>\n",
       "      <td>76.987719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>iota_b8_f32_kv8192</td>\n",
       "      <td>rt-gemma3</td>\n",
       "      <td>8</td>\n",
       "      <td>f32</td>\n",
       "      <td>8192</td>\n",
       "      <td>18.66280</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.429</td>\n",
       "      <td>418648</td>\n",
       "      <td>43.503030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>kappa_b8_f32_kv0</td>\n",
       "      <td>rt-gemma3</td>\n",
       "      <td>8</td>\n",
       "      <td>f32</td>\n",
       "      <td>0</td>\n",
       "      <td>18.70150</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.430</td>\n",
       "      <td>420231</td>\n",
       "      <td>43.491860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>theta_b8_f32_kv4096</td>\n",
       "      <td>rt-gemma3</td>\n",
       "      <td>8</td>\n",
       "      <td>f32</td>\n",
       "      <td>4096</td>\n",
       "      <td>18.66390</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.431</td>\n",
       "      <td>418916</td>\n",
       "      <td>43.303712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>beta_b8_bf16_kv0</td>\n",
       "      <td>mistral</td>\n",
       "      <td>8</td>\n",
       "      <td>bf16</td>\n",
       "      <td>0</td>\n",
       "      <td>13.64180</td>\n",
       "      <td>2.917</td>\n",
       "      <td>3.045</td>\n",
       "      <td>3.082</td>\n",
       "      <td>3.165</td>\n",
       "      <td>2926345</td>\n",
       "      <td>4.310205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>eta_b8_f16_kv4096</td>\n",
       "      <td>gemma3</td>\n",
       "      <td>8</td>\n",
       "      <td>f16</td>\n",
       "      <td>4096</td>\n",
       "      <td>4.58020</td>\n",
       "      <td>1.741</td>\n",
       "      <td>1.746</td>\n",
       "      <td>1.747</td>\n",
       "      <td>1.749</td>\n",
       "      <td>1749885</td>\n",
       "      <td>2.618754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gama_b8_bf16_kv128</td>\n",
       "      <td>gemma3</td>\n",
       "      <td>8</td>\n",
       "      <td>bf16</td>\n",
       "      <td>128</td>\n",
       "      <td>4.55551</td>\n",
       "      <td>1.747</td>\n",
       "      <td>1.750</td>\n",
       "      <td>1.751</td>\n",
       "      <td>1.753</td>\n",
       "      <td>1756092</td>\n",
       "      <td>2.598694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>eta_b8_bf16_kv4096</td>\n",
       "      <td>gemma3</td>\n",
       "      <td>8</td>\n",
       "      <td>bf16</td>\n",
       "      <td>4096</td>\n",
       "      <td>4.50612</td>\n",
       "      <td>1.768</td>\n",
       "      <td>1.771</td>\n",
       "      <td>1.773</td>\n",
       "      <td>1.776</td>\n",
       "      <td>1774836</td>\n",
       "      <td>2.537230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>beta_b8_bf16_kv0</td>\n",
       "      <td>gemma3</td>\n",
       "      <td>8</td>\n",
       "      <td>bf16</td>\n",
       "      <td>0</td>\n",
       "      <td>4.49378</td>\n",
       "      <td>1.765</td>\n",
       "      <td>1.774</td>\n",
       "      <td>1.774</td>\n",
       "      <td>1.776</td>\n",
       "      <td>1775727</td>\n",
       "      <td>2.530282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>delta_b8_bf16_kv256</td>\n",
       "      <td>gemma3</td>\n",
       "      <td>8</td>\n",
       "      <td>bf16</td>\n",
       "      <td>256</td>\n",
       "      <td>4.77773</td>\n",
       "      <td>1.671</td>\n",
       "      <td>1.674</td>\n",
       "      <td>1.675</td>\n",
       "      <td>2.197</td>\n",
       "      <td>1676417</td>\n",
       "      <td>2.174661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T10:31:49.587325Z",
     "start_time": "2025-07-22T10:31:49.580201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from the best rows get the best for each model\n",
    "best_per_model = best_rows.loc[best_rows.groupby('model')['throughput_latency_ratio'].idxmax()]\n",
    "best_per_model = best_per_model.sort_values(by='throughput_latency_ratio', ascending=False)\n",
    "# Reset index for better readability\n",
    "best_per_model.reset_index(drop=True, inplace=True)\n",
    "# Display the best rows\n",
    "best_per_model.head(20)\n",
    "\n",
    "# remove batch size. p50 latency, p90 latency, response wait\n",
    "best_per_model = best_per_model.drop(columns=['p50 latency', 'p90 latency', 'p95 latency', 'response wait'])\n",
    "# Display the best rows\n",
    "best_per_model.reset_index(drop=True, inplace=True)\n",
    "best_per_model"
   ],
   "id": "cb0fa4408fca53d2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                 test          model  batch_size floating_point  kv_cache  \\\n",
       "0  iota_b1_f32_kv8192     rt-mistral           1            f32      8192   \n",
       "1  iota_b4_f32_kv8192  rt-meta-llama           4            f32      8192   \n",
       "2  iota_b1_f32_kv8192      rt-gemma3           1            f32      8192   \n",
       "3    beta_b8_bf16_kv0        mistral           8           bf16         0   \n",
       "4   eta_b8_f16_kv4096         gemma3           8            f16      4096   \n",
       "5    beta_b8_bf16_kv0     meta-llama           8           bf16         0   \n",
       "\n",
       "   Inferences/Second  p99 latency  throughput_latency_ratio  \n",
       "0         5969.22000        0.023             259531.304348  \n",
       "1         2906.76000        0.041              70896.585366  \n",
       "2           13.49860        0.077                175.306494  \n",
       "3           13.64180        3.165                  4.310205  \n",
       "4            4.58020        1.749                  2.618754  \n",
       "5            9.02461        5.139                  1.756102  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>model</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>floating_point</th>\n",
       "      <th>kv_cache</th>\n",
       "      <th>Inferences/Second</th>\n",
       "      <th>p99 latency</th>\n",
       "      <th>throughput_latency_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iota_b1_f32_kv8192</td>\n",
       "      <td>rt-mistral</td>\n",
       "      <td>1</td>\n",
       "      <td>f32</td>\n",
       "      <td>8192</td>\n",
       "      <td>5969.22000</td>\n",
       "      <td>0.023</td>\n",
       "      <td>259531.304348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iota_b4_f32_kv8192</td>\n",
       "      <td>rt-meta-llama</td>\n",
       "      <td>4</td>\n",
       "      <td>f32</td>\n",
       "      <td>8192</td>\n",
       "      <td>2906.76000</td>\n",
       "      <td>0.041</td>\n",
       "      <td>70896.585366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iota_b1_f32_kv8192</td>\n",
       "      <td>rt-gemma3</td>\n",
       "      <td>1</td>\n",
       "      <td>f32</td>\n",
       "      <td>8192</td>\n",
       "      <td>13.49860</td>\n",
       "      <td>0.077</td>\n",
       "      <td>175.306494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beta_b8_bf16_kv0</td>\n",
       "      <td>mistral</td>\n",
       "      <td>8</td>\n",
       "      <td>bf16</td>\n",
       "      <td>0</td>\n",
       "      <td>13.64180</td>\n",
       "      <td>3.165</td>\n",
       "      <td>4.310205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eta_b8_f16_kv4096</td>\n",
       "      <td>gemma3</td>\n",
       "      <td>8</td>\n",
       "      <td>f16</td>\n",
       "      <td>4096</td>\n",
       "      <td>4.58020</td>\n",
       "      <td>1.749</td>\n",
       "      <td>2.618754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>beta_b8_bf16_kv0</td>\n",
       "      <td>meta-llama</td>\n",
       "      <td>8</td>\n",
       "      <td>bf16</td>\n",
       "      <td>0</td>\n",
       "      <td>9.02461</td>\n",
       "      <td>5.139</td>\n",
       "      <td>1.756102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cc74bdbaf0a0c7cd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
